# -----------------------------------
# ğŸ“Œ STEP 0. ì„í¬íŠ¸
# -----------------------------------
import numpy as np
import tensorflow as tf
import cv2
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, TimeDistributed, Conv1D, BatchNormalization, LSTM, Dense, Lambda, Reshape
from tensorflow.keras import backend as K

# -----------------------------------
# ğŸ“Œ STEP 3. ì´ë¯¸ì§€ â†’ ì‹œê³„ì—´ feature ì¶”ì¶œ
# -----------------------------------
def extract_features_from_image(img):
    # ì´ë¯¸ì§€ê°€ ì»¬ëŸ¬ì¸ ê²½ìš° ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    img = cv2.resize(img, (300, 300))
    blur = cv2.GaussianBlur(img, (5, 5), 0)
    edges = cv2.Canny(blur, 30, 100)

    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    # ì»¨íˆ¬ì–´ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not contours:
        print("âš ï¸ ì»¨íˆ¬ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        # ë¹ˆ ì»¨íˆ¬ì–´ ëŒ€ì‹  ì„ì˜ì˜ ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ ìƒì„±
        contour_points = np.random.randint(0, 300, size=(150, 2))
    else:
        contour_points = np.concatenate(contours, axis=0).squeeze()

        # contour_pointsê°€ 1ì°¨ì›ì¸ ê²½ìš° (ë‹¨ì¼ í¬ì¸íŠ¸)
        if contour_points.ndim == 1:
            contour_points = contour_points.reshape(1, 2)

        # í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•œ ê²½ìš° íŒ¨ë”©
        if len(contour_points) < 150:
            # ë§ˆì§€ë§‰ í¬ì¸íŠ¸ë¥¼ ë³µì œí•˜ì—¬ íŒ¨ë”©
            pad_length = 150 - len(contour_points)
            contour_points = np.vstack([contour_points,
                                        np.tile(contour_points[-1], (pad_length, 1))])

    # í¬ì¸íŠ¸ê°€ ì¶©ë¶„í•œ ê²½ìš° ëœë¤ ìƒ˜í”Œë§
    if len(contour_points) > 150:
        selected = contour_points[np.random.choice(len(contour_points), 150, replace=False)]
    else:
        selected = contour_points[:150]

    # íŠ¹ì„± ì¶”ì¶œ
    features = np.stack([
        selected[:, 0], selected[:, 1],  # x, y
        np.gradient(selected[:, 0]),  # dx
        np.gradient(selected[:, 1]),  # dy
    ], axis=-1)  # (150, 4)

    # 24ê°œ íŠ¹ì„±ìœ¼ë¡œ í™•ì¥
    while features.shape[1] < 24:
        features = np.concatenate([features, features], axis=1)
    features = features[:, :24]

    # ì •ê·œí™”
    std = np.std(features, axis=0)
    mean = np.mean(features, axis=0)
    features = (features - mean) / (std + 1e-8)

    return features.astype(np.float32).reshape(150, 24, 1)

# -----------------------------------
# ğŸ“Œ STEP 4. Siamese ëª¨ë¸ ì •ì˜
# -----------------------------------
def euclidean_distance(vects):
    x, y = vects
    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))

def net(input_shape, timeseries_n, feature_l):
    input_layer = Input(shape=input_shape)  # (150, 24, 1)

    conv1 = Conv1D(32, 5, activation='gelu', padding='same')
    x = TimeDistributed(conv1)(input_layer)  # (150, 24, 32)
    x = BatchNormalization()(x)

    conv2 = Conv1D(1, 1, activation='gelu')
    x = TimeDistributed(conv2)(x)  # (150, 24, 1)
    x = BatchNormalization()(x)

    x = Reshape((timeseries_n, feature_l))(x)  # (150, 24)

    x = LSTM(feature_l, return_sequences=True)(x)
    x = LSTM(32, return_sequences=False)(x)

    x = Dense(8, activation='gelu')(x)

    return Model(inputs=input_layer, outputs=x)

def create_full_model(input_shape):
    base_network = net(input_shape, timeseries_n=150, feature_l=24)

    input_a = Input(shape=input_shape)
    input_b = Input(shape=input_shape)

    vec_a = base_network(input_a)
    vec_b = base_network(input_b)

    distance = Lambda(euclidean_distance)([vec_a, vec_b])

    return Model(inputs=[input_a, input_b], outputs=distance)

def analyze():

    try:
        font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'  # ë§¥OS ê¸°ë³¸ í•œê¸€ í°íŠ¸
        if os.path.exists(font_path):
            plt.rcParams['font.family'] = 'AppleGothic'
        else:
            # ë‹¤ë¥¸ í•œê¸€ í°íŠ¸ ê²€ìƒ‰
            korean_fonts = [f for f in fm.findSystemFonts(fontpaths=None) if any(name in f for name in
                                                                                ['Gothic', 'Batang', 'Myeongjo', 'Gulim',
                                                                                'Dotum', 'Malgun', 'NanumGothic',
                                                                                'NanumMyeongjo'])]
            if korean_fonts:
                plt.rcParams['font.family'] = fm.FontProperties(fname=korean_fonts[0]).get_name()
            else:
                print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•œê¸€ì´ ê¹¨ì ¸ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("âš ï¸ í°íŠ¸ ë¬¸ì œë¡œ í•œê¸€ì´ ê¹¨ì ¸ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # -----------------------------------
    # ğŸ“Œ STEP 2. ê²½ë¡œ ì„¤ì • ë° ê²€ì¦
    # -----------------------------------
    # ì°¸ì¡° ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë”ì™€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ
    reference_dir = 'reference_samples'
    test_dir = 'test_samples'
    model_path = 'our.net.hdf5'  # í˜„ì¬ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°

    # ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(reference_dir):
        print(f"âš ï¸ ì°¸ì¡° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {reference_dir}")
        os.makedirs(reference_dir)
        print(f"ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        exit(1)

    if not os.path.exists(test_dir):
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {test_dir}")
        os.makedirs(test_dir)
        print(f"ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        exit(1)

    # ì°¸ì¡° ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡
    reference_img_paths = [os.path.join(reference_dir, f) for f in os.listdir(reference_dir)
                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not reference_img_paths:
        print(f"âš ï¸ ì°¸ì¡° ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {reference_dir}")
        print("ì§€ì› í˜•ì‹: PNG, JPG, JPEG")
        exit(1)

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡
    test_img_paths = [os.path.join(test_dir, f) for f in os.listdir(test_dir)
                    if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not test_img_paths:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {test_dir}")
        print("ì§€ì› í˜•ì‹: PNG, JPG, JPEG")
        exit(1)

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì„ íƒ (ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì‚¬ìš©)
    test_img_path = test_img_paths[0]
    print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {os.path.basename(test_img_path)}")
    print(f"ì°¸ì¡° ì´ë¯¸ì§€ ìˆ˜: {len(reference_img_paths)}")

    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(model_path):
        print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì§€ì •ëœ ê²½ë¡œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
        # í”„ë¡œì íŠ¸ í´ë”ì—ì„œ hdf5 íŒŒì¼ ì°¾ê¸°
        found_models = []
        for root, dirs, files in os.walk('.'):
            for file in files:
                if file.endswith('.hdf5') or file.endswith('.h5'):
                    found_models.append(os.path.join(root, file))

        if found_models:
            print("ğŸ’¡ ë‹¤ìŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
            for i, found_model in enumerate(found_models):
                print(f"  {i + 1}. {found_model}")

            choice = input("ì‚¬ìš©í•  ëª¨ë¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë˜ëŠ” që¡œ ì¢…ë£Œ): ")
            if choice.lower() == 'q':
                exit(1)
            try:
                model_path = found_models[int(choice) - 1]
                print(f"ì„ íƒí•œ ëª¨ë¸: {model_path}")
            except (ValueError, IndexError):
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                exit(1)
        else:
            print("ğŸ’¡ í”„ë¡œì íŠ¸ í´ë”ì—ì„œ .hdf5 ë˜ëŠ” .h5 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            custom_path = input("ëª¨ë¸ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ë˜ëŠ” që¡œ ì¢…ë£Œ): ")
            if custom_path.lower() == 'q':
                exit(1)
            model_path = custom_path
            if not os.path.exists(model_path):
                print(f"ì…ë ¥í•œ ê²½ë¡œì— íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
                print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                exit(1)

    # -----------------------------------
    # ğŸ“Œ STEP 5. ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë”©
    # -----------------------------------
    input_shape = (150, 24, 1)
    model = create_full_model(input_shape)

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    try:
        model.load_weights(model_path)
        print(f"âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {model_path}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        exit(1)

    # -----------------------------------
    # ğŸ“Œ STEP 6. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ì°¸ì¡° ì´ë¯¸ì§€ë“¤ ë¹„êµ
    # -----------------------------------
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¡œë“œ ë° íŠ¹ì„± ì¶”ì¶œ
    test_img = cv2.imread(test_img_path)
    if test_img is None:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_img_path}")
        exit(1)

    test_feat = np.expand_dims(extract_features_from_image(test_img), axis=0)  # (1, 150, 24, 1)

    # ì„ê³„ê°’ ì„¤ì •
    threshold = 0.2

    # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
    results = []

    # ê° ì°¸ì¡° ì´ë¯¸ì§€ì™€ ë¹„êµ
    for ref_path in reference_img_paths:
        # ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ
        ref_img = cv2.imread(ref_path)
        if ref_img is None:
            print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ref_path}")
            continue

        # íŠ¹ì„± ì¶”ì¶œ
        ref_feat = np.expand_dims(extract_features_from_image(ref_img), axis=0)

        # ê±°ë¦¬ ê³„ì‚°
        distance = model.predict([test_feat, ref_feat], verbose=0)[0][0]

        # ê°™ì€ ì‚¬ëŒì¸ì§€ íŒë³„
        is_same = distance < threshold
        result = "ê°™ì€ ì‚¬ëŒ" if is_same else "ë‹¤ë¥¸ ì‚¬ëŒ"

        # ê²°ê³¼ ì €ì¥
        results.append({
            'reference_image': os.path.basename(ref_path),
            'distance': distance,
            'result': result,
            'is_same': is_same,
            'ref_img': ref_img if len(ref_img.shape) == 2 else cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)
        })

        print(f"ì°¸ì¡° ì´ë¯¸ì§€ '{os.path.basename(ref_path)}' ë¹„êµ ê²°ê³¼: ê±°ë¦¬={distance:.4f}, {result}")

    # ê²°ê³¼ë¥¼ ê±°ë¦¬ìˆœìœ¼ë¡œ ì •ë ¬
    results.sort(key=lambda x: x['distance'])

    # -----------------------------------
    # ğŸ“Œ STEP 7. ê²°ê³¼ ì‹œê°í™”
    # -----------------------------------
    # ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not results:
        print("âŒ ë¹„êµí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    if len(test_img.shape) == 3:
        test_img_gray = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)
    else:
        test_img_gray = test_img

    # ìƒìœ„ 5ê°œ ë˜ëŠ” ì „ì²´ ê²°ê³¼ (ë” ì ì€ ìª½) í‘œì‹œ
    display_count = min(5, len(results))

    plt.figure(figsize=(15, 3 * display_count))

    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ (í•­ìƒ ì™¼ìª½ì— í‘œì‹œ)
    plt.subplot(display_count, 3, 1)
    plt.imshow(test_img_gray, cmap='gray')
    plt.title("Test Image", fontsize=12)  # ì˜ì–´ë¡œ í‘œì‹œí•˜ì—¬ í°íŠ¸ ë¬¸ì œ íšŒí”¼
    plt.axis('off')

    # ê° ì°¸ì¡° ì´ë¯¸ì§€ ë° ê²°ê³¼ í‘œì‹œ
    for i in range(display_count):
        result = results[i]

        # ì°¸ì¡° ì´ë¯¸ì§€
        plt.subplot(display_count, 3, i * 3 + 2)
        plt.imshow(result['ref_img'], cmap='gray')
        plt.title(f"Reference: {result['reference_image']}", fontsize=10)  # ì˜ì–´ë¡œ í‘œì‹œ
        plt.axis('off')

        # ê²°ê³¼ í…ìŠ¤íŠ¸
        plt.subplot(display_count, 3, i * 3 + 3)
        result_text = f"Distance: {result['distance']:.4f}\nResult: "
        result_text += "Same Person" if result['is_same'] else "Different Person"  # ì˜ì–´ë¡œ í‘œì‹œ

        plt.text(0.5, 0.5, result_text,
                horizontalalignment='center', verticalalignment='center', fontsize=12)
        plt.axis('off')

        # ë°°ê²½ìƒ‰ ì„¤ì • (ê°™ì€ ì‚¬ëŒì´ë©´ ì—°í•œ ë…¹ìƒ‰, ë‹¤ë¥¸ ì‚¬ëŒì´ë©´ ì—°í•œ ë¹¨ê°„ìƒ‰)
        if result['is_same']:
            plt.gca().set_facecolor((0.9, 1, 0.9))  # ì—°í•œ ë…¹ìƒ‰
        else:
            plt.gca().set_facecolor((1, 0.9, 0.9))  # ì—°í•œ ë¹¨ê°„ìƒ‰

    plt.tight_layout()
    plt.show()

    # ì¢…í•© ê²°ê³¼ ì¶œë ¥
    same_person_count = sum(1 for r in results if r['is_same'])
    print(f"\nê²°ê³¼ ìš”ì•½: ì´ {len(results)}ê°œ ì°¸ì¡° ì´ë¯¸ì§€ ì¤‘ {same_person_count}ê°œê°€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ê°™ì€ ì‚¬ëŒìœ¼ë¡œ íŒë³„ë¨")

    # ê°€ì¥ ìœ ì‚¬í•œ ì°¸ì¡° ì´ë¯¸ì§€ ê²°ê³¼
    if results:
        best_match = results[0]
        print(
            f"ê°€ì¥ ìœ ì‚¬í•œ ì°¸ì¡° ì´ë¯¸ì§€: {best_match['reference_image']} (ê±°ë¦¬: {best_match['distance']:.4f}, ê²°ê³¼: {best_match['result']})")