import numpy as np
import os
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, TimeDistributed, Conv1D, BatchNormalization, LSTM, Dense, Lambda, Reshape
from tensorflow.keras import backend as K
import math
import pytesseract
from pytesseract import Output

from app.models.analyzeResponse import AnalyzeResponse


# ğŸ“Œ STEP 3. ì´ë¯¸ì§€ ì¤„ ì¶”ì¶œ í•¨ìˆ˜
def extract_lines_from_image(img):
    # ì´ë¯¸ì§€ê°€ ì»¬ëŸ¬ì¸ ê²½ìš° ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # ì´ë¯¸ì§€ ì´ì§„í™” (ì ì‘í˜• ì„ê³„ê°’ ì‚¬ìš©)
    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)

    # ìˆ˜í‰ íˆ¬ì˜ í”„ë¡œí•„ ê³„ì‚°
    h_proj = np.sum(binary, axis=1)

    # ì¤„ ê²½ê³„ ì°¾ê¸°
    line_boundaries = []
    in_line = False
    line_start = 0

    # ìµœì†Œ ì¤„ ë†’ì´ (ë…¸ì´ì¦ˆ í•„í„°ë§ ìš©)
    min_line_height = img.shape[0] * 0.02  # ì´ë¯¸ì§€ ë†’ì´ì˜ 2%

    for i, proj in enumerate(h_proj):
        if not in_line and proj > 0:
            # ì¤„ ì‹œì‘
            in_line = True
            line_start = i
        elif in_line and (proj == 0 or i == len(h_proj) - 1):
            # ì¤„ ë
            in_line = False
            line_end = i

            # ìµœì†Œ ë†’ì´ë³´ë‹¤ í° ì¤„ë§Œ ì €ì¥
            if line_end - line_start > min_line_height:
                line_boundaries.append((line_start, line_end))

    # ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ì¤„ ì¶”ì¶œ
    lines = []
    for start, end in line_boundaries:
        # ì•½ê°„ì˜ ì—¬ë°±ì„ ì¶”ê°€í•˜ì—¬ ì¤„ ì¶”ì¶œ
        padding = 5
        start_padded = max(0, start - padding)
        end_padded = min(img.shape[0], end + padding)

        line_img = img[start_padded:end_padded, :]
        lines.append(line_img)

    return lines

def extract_lines_with_ocr(img):
    """
    ê°œì„ ëœ Tesseract OCR ê¸°ë°˜ ì¤„ ì¶”ì¶œ í•¨ìˆ˜:
    - ë¹¨ê°„ í…Œë‘ë¦¬ ì œê±°
    - ì¤„ ë‹¨ìœ„ ì¸ì‹ ê°•í™” (psm 6)
    - ì¤„ë³„ bounding boxë¡œ ì˜ë¼ë‚´ê¸°
    """
    # 1. ë¹¨ê°„ í…Œë‘ë¦¬ ì œê±°
    if len(img.shape) == 3 and img.shape[2] == 3:
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        mask_red = cv2.inRange(hsv, (0, 70, 50), (10, 255, 255)) + \
                   cv2.inRange(hsv, (170, 70, 50), (180, 255, 255))
        img[mask_red > 0] = (255, 255, 255)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img.copy()

    # 2. Tesseract OCRë¡œ ì¤„ ë‹¨ìœ„ ì¸ì‹
    custom_config = r'--psm 6'
    ocr_data = pytesseract.image_to_data(gray, config=custom_config, output_type=Output.DICT)

    lines = []
    last_line_num = -1
    line_group = []

    for i in range(len(ocr_data['text'])):
        text = ocr_data['text'][i].strip()
        line_num = ocr_data['line_num'][i]

        if text == '':
            continue

        x, y, w, h = ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i]

        if line_num == last_line_num:
            line_group.append((x, y, w, h))
        else:
            if line_group:
                lines.append(line_group)
            line_group = [(x, y, w, h)]
            last_line_num = line_num

    if line_group:
        lines.append(line_group)

    # 3. ê° ì¤„ ì˜ì—­ì„ ì˜ë¼ì„œ ë°˜í™˜
    line_images = []
    for group in lines:
        xs = [x for x, y, w, h in group]
        ys = [y for x, y, w, h in group]
        ws = [w for x, y, w, h in group]
        hs = [h for x, y, w, h in group]

        x_min = max(0, min(xs) - 5)
        y_min = max(0, min(ys) - 5)
        x_max = min(gray.shape[1], max(x + w for x, w in zip(xs, ws)) + 5)
        y_max = min(gray.shape[0], max(y + h for y, h in zip(ys, hs)) + 5)

        line_img = gray[y_min:y_max, x_min:x_max]
        line_images.append(line_img)

    return line_images

# ğŸ“Œ STEP 4. ì´ë¯¸ì§€ â†’ ì‹œê³„ì—´ feature ì¶”ì¶œ
def extract_features_from_image(img):
    # ì´ë¯¸ì§€ê°€ ì»¬ëŸ¬ì¸ ê²½ìš° ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    if len(img.shape) == 3 and img.shape[2] == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    img = cv2.resize(img, (300, 300))
    blur = cv2.GaussianBlur(img, (5, 5), 0)
    edges = cv2.Canny(blur, 30, 100)

    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    # ì»¨íˆ¬ì–´ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not contours:
        print("âš ï¸ ì»¨íˆ¬ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        # ë¹ˆ ì»¨íˆ¬ì–´ ëŒ€ì‹  ì„ì˜ì˜ ë…¸ì´ì¦ˆ í¬ì¸íŠ¸ ìƒì„±
        contour_points = np.random.randint(0, 300, size=(150, 2))
    else:
        contour_points = np.concatenate(contours, axis=0).squeeze()

        # contour_pointsê°€ 1ì°¨ì›ì¸ ê²½ìš° (ë‹¨ì¼ í¬ì¸íŠ¸)
        if contour_points.ndim == 1:
            contour_points = contour_points.reshape(1, 2)

        # í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•œ ê²½ìš° íŒ¨ë”©
        if len(contour_points) < 150:
            # ë§ˆì§€ë§‰ í¬ì¸íŠ¸ë¥¼ ë³µì œí•˜ì—¬ íŒ¨ë”©
            pad_length = 150 - len(contour_points)
            contour_points = np.vstack([contour_points,
                                        np.tile(contour_points[-1], (pad_length, 1))])

    # í¬ì¸íŠ¸ê°€ ì¶©ë¶„í•œ ê²½ìš° ëœë¤ ìƒ˜í”Œë§
    if len(contour_points) > 150:
        selected = contour_points[np.random.choice(len(contour_points), 150, replace=False)]
    else:
        selected = contour_points[:150]

    # íŠ¹ì„± ì¶”ì¶œ
    features = np.stack([
        selected[:, 0], selected[:, 1],  # x, y
        np.gradient(selected[:, 0]),  # dx
        np.gradient(selected[:, 1]),  # dy
    ], axis=-1)  # (150, 4)

    # 24ê°œ íŠ¹ì„±ìœ¼ë¡œ í™•ì¥
    while features.shape[1] < 24:
        features = np.concatenate([features, features], axis=1)
    features = features[:, :24]

    # ì •ê·œí™”
    std = np.std(features, axis=0)
    mean = np.mean(features, axis=0)
    features = (features - mean) / (std + 1e-8)

    return features.astype(np.float32).reshape(150, 24, 1)

# ğŸ“Œ STEP 5. Siamese ëª¨ë¸ ì •ì˜
def euclidean_distance(vects):
    x, y = vects
    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))


def net(input_shape, timeseries_n, feature_l):
    input_layer = Input(shape=input_shape)  # (150, 24, 1)

    conv1 = Conv1D(32, 5, activation='gelu', padding='same')
    x = TimeDistributed(conv1)(input_layer)  # (150, 24, 32)
    x = BatchNormalization()(x)

    conv2 = Conv1D(1, 1, activation='gelu')
    x = TimeDistributed(conv2)(x)  # (150, 24, 1)
    x = BatchNormalization()(x)

    x = Reshape((timeseries_n, feature_l))(x)  # (150, 24)

    x = LSTM(feature_l, return_sequences=True)(x)
    x = LSTM(32, return_sequences=False)(x)

    x = Dense(8, activation='gelu')(x)

    return Model(inputs=input_layer, outputs=x)


def create_full_model(input_shape):
    base_network = net(input_shape, timeseries_n=150, feature_l=24)

    input_a = Input(shape=input_shape)
    input_b = Input(shape=input_shape)

    vec_a = base_network(input_a)
    vec_b = base_network(input_b)

    distance = Lambda(euclidean_distance)([vec_a, vec_b])

    return Model(inputs=[input_a, input_b], outputs=distance)

# ğŸ“Œ STEP 7. ì¤„ ë³„ ë¹„êµ í•¨ìˆ˜
def compare_lines(model, test_lines, ref_lines, threshold=0.2):
    """
    í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ê° ì¤„ê³¼ ì°¸ì¡° ì´ë¯¸ì§€ì˜ ê° ì¤„ì„ ë¹„êµí•˜ì—¬ ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„±
    """
    similarity_matrix = np.zeros((len(test_lines), len(ref_lines)))

    for i, test_line in enumerate(test_lines):
        # í…ŒìŠ¤íŠ¸ ì¤„ì˜ íŠ¹ì„± ì¶”ì¶œ
        test_feat = np.expand_dims(extract_features_from_image(test_line), axis=0)

        for j, ref_line in enumerate(ref_lines):
            # ì°¸ì¡° ì¤„ì˜ íŠ¹ì„± ì¶”ì¶œ
            ref_feat = np.expand_dims(extract_features_from_image(ref_line), axis=0)

            # ê±°ë¦¬ ê³„ì‚°
            distance = model.predict([test_feat, ref_feat], verbose=0)[0][0]

            # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ìŒ)
            # ê±°ë¦¬ê°€ 0ì´ë©´ ì™„ì „íˆ ì¼ì¹˜, ê±°ë¦¬ê°€ í´ìˆ˜ë¡ ì°¨ì´ê°€ ì»¤ì§
            # ìœ ì‚¬ë„ë¥¼ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™” (0: ì™„ì „íˆ ë‹¤ë¦„, 1: ì™„ì „íˆ ì¼ì¹˜)
            similarity = math.exp(-distance * 5)  # ì§€ìˆ˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ 0~1 ë²”ìœ„ë¡œ ë§¤í•‘
            similarity_matrix[i, j] = similarity

    return similarity_matrix

# ğŸ“Œ STEP 8. ìœ ì‚¬ë„ í–‰ë ¬ ê¸°ë°˜ ë§¤ì¹­ ìˆ˜í–‰
def find_best_matches(similarity_matrix):
    """
    ìœ ì‚¬ë„ í–‰ë ¬ì—ì„œ ê° í…ŒìŠ¤íŠ¸ ì¤„ì— ëŒ€í•œ ê°€ì¥ ìœ ì‚¬í•œ ì°¸ì¡° ì¤„ ì°¾ê¸°
    """
    best_matches = []
    # ê° í…ŒìŠ¤íŠ¸ ì¤„ì— ëŒ€í•´ ìµœê³  ìœ ì‚¬ë„ì™€ í•´ë‹¹ ì°¸ì¡° ì¤„ ì¸ë±ìŠ¤ ì°¾ê¸°
    for i in range(similarity_matrix.shape[0]):
        best_ref_idx = np.argmax(similarity_matrix[i])
        best_similarity = similarity_matrix[i, best_ref_idx]
        best_matches.append((i, best_ref_idx, best_similarity))

    return best_matches


# ğŸ“Œ STEP 9. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ì°¸ì¡° ì´ë¯¸ì§€ë“¤ ë¹„êµ (ìˆ˜ì •ë¨)
def extract_pressure_slant_features(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img.copy()
    binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]

    # í•„ì•• ì¶”ì •: í‰ê·  ë°ê¸° (ê²€ì€ìƒ‰ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í•„ì••ì´ ì§„í•¨)
    pressure_score = np.mean(binary) / 255.0  # 0~1ë¡œ ì •ê·œí™”

    # ê¸°ìš¸ê¸° ì¶”ì •: Hough transformì„ ì‚¬ìš©í•œ ë¼ì¸ ê¸°ìš¸ê¸°
    edges = cv2.Canny(binary, 50, 150, apertureSize=3)
    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)
    if lines is not None:
        angles = [(theta - np.pi / 2) for rho, theta in lines[:, 0]]
        slant_score = np.mean(np.abs(angles)) / (np.pi / 4)  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
    else:
        slant_score = 0.0

    return pressure_score, slant_score


def check_directories_and_model(reference_dir, test_dir, model_path):
    for dir_path in [reference_dir, test_dir]:
        if not os.path.exists(dir_path):
            print(f"âš ï¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dir_path}")
            os.makedirs(dir_path)
            print(f"ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤: {dir_path}")
            exit(1)

    if not os.path.exists(model_path):
        print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        found_models = []
        for root, dirs, files in os.walk('.'):
            for file in files:
                if file.endswith(('.hdf5', '.h5')):
                    found_models.append(os.path.join(root, file))
        if not found_models:
            custom_path = input("ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì…ë ¥ (që¡œ ì¢…ë£Œ): ")
            if custom_path.lower() == 'q' or not os.path.exists(custom_path):
                exit(1)
            model_path = custom_path
        else:
            for i, model in enumerate(found_models):
                print(f"{i + 1}. {model}")
            choice = input("ì‚¬ìš©í•  ëª¨ë¸ ë²ˆí˜¸ ì…ë ¥ (që¡œ ì¢…ë£Œ): ")
            if choice.lower() == 'q':
                exit(1)
            model_path = found_models[int(choice) - 1]
    return model_path


def load_images(reference_dir, test_dir):
    reference_img_paths = [os.path.join(reference_dir, f) for f in os.listdir(reference_dir)
                           if f.lower().endswith(('png', 'jpg', 'jpeg'))]
    test_img_paths = [os.path.join(test_dir, f) for f in os.listdir(test_dir)
                      if f.lower().endswith(('png', 'jpg', 'jpeg'))]

    if not reference_img_paths:
        print(f"âš ï¸ ì°¸ì¡° ì´ë¯¸ì§€ ì—†ìŒ: {reference_dir}")
        exit(1)
    if not test_img_paths:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì—†ìŒ: {test_dir}")
        exit(1)

    test_img_path = test_img_paths[0]
    print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {os.path.basename(test_img_path)}")
    print(f"ì°¸ì¡° ì´ë¯¸ì§€ ìˆ˜: {len(reference_img_paths)}")
    return reference_img_paths, test_img_path


def build_and_load_model(model_path):
    input_shape = (150, 24, 1)
    model = create_full_model(input_shape)
    try:
        model.load_weights(model_path)
        print(f"âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {model_path}")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        exit(1)
    return model


def analyze_images(model, reference_img_paths, test_img_path, threshold=0.5):
    results = []
    test_img = cv2.imread(test_img_path)

    for ref_path in reference_img_paths:
        ref_img = cv2.imread(ref_path)
        if ref_img is None or test_img is None:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {ref_path} ë˜ëŠ” {test_img_path}")
            continue

        test_lines = extract_lines_with_ocr(test_img)
        ref_lines = extract_lines_with_ocr(ref_img)

        if not test_lines or not ref_lines:
            print(f"âš ï¸ ì¤„ ì¶”ì¶œ ì‹¤íŒ¨: {ref_path}")
            continue

        similarity_matrix = compare_lines(model, test_lines, ref_lines)
        avg_similarity = np.mean(similarity_matrix)
        best_match_avg = np.mean([np.max(similarity_matrix[i]) for i in range(similarity_matrix.shape[0])])

        pressure_scores, slant_scores = [], []
        for line in test_lines + ref_lines:
            pressure, slant = extract_pressure_slant_features(line)
            pressure_scores.append(pressure)
            slant_scores.append(slant)

        avg_pressure = np.mean(pressure_scores)
        avg_slant = np.mean(slant_scores)

        is_same = avg_similarity > threshold
        result = "ê°™ì€ ë¬¸ì„œ" if is_same else "ë‹¤ë¥¸ ë¬¸ì„œ"

        results.append({
            'reference_image': os.path.basename(ref_path),
            'avg_similarity': avg_similarity,
            'best_match_avg': best_match_avg,
            'avg_pressure': avg_pressure,
            'avg_slant': avg_slant,
            'result': result,
            'is_same': is_same,
            'similarity_matrix': similarity_matrix,
            'ref_img': ref_img,
            'test_lines': test_lines,
            'ref_lines': ref_lines,
            'best_matches': find_best_matches(similarity_matrix)
        })

    results.sort(key=lambda x: x['best_match_avg'], reverse=True)
    return results, test_img

def create_result(results):
    if not results:
        print("âŒ ë¹„êµí•  ê²°ê³¼ ì—†ìŒ")
        exit(1)

    best_result = results[0]

    return AnalyzeResponse(best_result['avg_similarity'], best_result['avg_pressure'], best_result['avg_slant'], "")

def analyze():
    reference_dir = 'ai/reference_samples'
    test_dir = 'ai/test_samples'
    model_path = 'ai/model/our_net.hdf5'

    model_path = check_directories_and_model(reference_dir, test_dir, model_path)
    reference_img_paths, test_img_path = load_images(reference_dir, test_dir)
    model = build_and_load_model(model_path)
    results, test_img = analyze_images(model, reference_img_paths, test_img_path)
    return create_result(results)
